{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91ff6b3",
   "metadata": {},
   "source": [
    "# Basic Data Types and Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdacdac",
   "metadata": {},
   "source": [
    "### Comments, Variables, and `print()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b01c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3.5\n",
      "3 3.5\n",
      "3\n",
      "3.5\n"
     ]
    }
   ],
   "source": [
    "# This is a comment as it starts with #\n",
    "\n",
    "'''\n",
    "This is a \n",
    "multiple-line \n",
    "comment\n",
    "'''\n",
    "\n",
    "\"\"\"\n",
    "This is another \n",
    "multiple-line \n",
    "comment\n",
    "\"\"\"\n",
    "\n",
    "# Python is a strongly-typed language, so the type matters when performing operations.\n",
    "# On the other hand, Python is a dynamically-typed language, so the variable type\n",
    "# is determined based on the data it holds in the runtime\n",
    "\n",
    "# python has a function called \"print()\" that prints variables based on their types\n",
    "\n",
    "# Integer variable\n",
    "x = 3\n",
    "print(x)\n",
    "\n",
    "# Float variable\n",
    "y = 3.5\n",
    "print(y)\n",
    "\n",
    "# print() can print multiple objects, and it takes a parameter called \"sep\" that is by default a space\n",
    "print(x, y)\n",
    "\n",
    "# in the next line, we set the \"sep\" parameter as a new line \"\\n\"\n",
    "print(x, y, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bea1ce",
   "metadata": {},
   "source": [
    "### Function `type()`\n",
    "you can use `type()` function to determine the type of the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86034e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'> <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x), type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e9236f",
   "metadata": {},
   "source": [
    "### Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f75b4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String with double quotes\n",
      "String with single quotes\n",
      "String with 'single quotes' in it\n",
      "String with \"double quotes\" in it\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# strings - both single or double quotes can be used to define strings\n",
    "z = \"String with double quotes\"\n",
    "w = 'String with single quotes'\n",
    "a = \"String with 'single quotes' in it\"\n",
    "b = 'String with \"double quotes\" in it'\n",
    "print(z, w, a, b, sep='\\n')\n",
    "print (type(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc2e3a2",
   "metadata": {},
   "source": [
    "### Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "770b8689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "x = str(3)\n",
    "y = int(\"3\")\n",
    "z = float(3)\n",
    "print(x, y, z, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf515be",
   "metadata": {},
   "source": [
    "### Boolean Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b662f242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False 1 0\n",
      "<class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "a = True\n",
    "b = False\n",
    "print(a, b, int(a), int(b))\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc254559",
   "metadata": {},
   "source": [
    "### Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e2ff82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the original list:                                [1, 'NLP', 2.3]\n",
      "This is the list after adding \"4\" to it:                  [1, 'NLP', 2.3, '4']\n",
      "This is the list after extending it with [5, 6]:          [1, 'NLP', 2.3, '4', 5, 6]\n",
      "This is the list after inserting \"0\" at index \"2\":        [1, 'NLP', 0, 2.3, '4', 5, 6]\n",
      "This is the list after removing \"NLP\" from it:              [1, 0, 2.3, '4', 5, 6]\n",
      "The list after removing the item of index 3, which is 4: [1, 0, 2.3, 5, 6]\n",
      "This is the list after sorting it:                        [0, 1, 2.3, 5, 6]\n",
      "This is the list after reversing it:                      [6, 5, 2.3, 1, 0]\n",
      "number of items in the list:                              5\n",
      "first item in the list:                                   6\n",
      "last item in the list:                                    0\n",
      "from item of index \"1\" to item of index \"2\":              [5, 2.3]\n",
      "from the first item to item of index \"1\":                 [6, 5]\n",
      "from item of index \"1\" to the last item:                  [5, 2.3, 1, 0]\n",
      "the list after changing the second item from \"NLP\" to 2:  [6, 2, 2.3, 1, 0]\n",
      "the list after removing the first item:                   [2, 2.3, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# a list can contain items of different types\n",
    "l = [1, \"NLP\", 2.3]\n",
    "print('This is the original list:                               ', l)\n",
    "\n",
    "# add item to list\n",
    "l.append(\"4\")\n",
    "print('This is the list after adding \"4\" to it:                 ', l)\n",
    "\n",
    "# extend list with another list\n",
    "l.extend([5, 6])\n",
    "print('This is the list after extending it with [5, 6]:         ', l)\n",
    "\n",
    "# insert item to list at a specific index\n",
    "l.insert(2, 0)\n",
    "print('This is the list after inserting \"0\" at index \"2\":       ', l)\n",
    "\n",
    "# remove item from list\n",
    "l.remove(\"NLP\")\n",
    "print('This is the list after removing \"NLP\" from it:             ', l)\n",
    "\n",
    "# remove item from list by index\n",
    "d=l.pop(3)\n",
    "print(f\"The list after removing the item of index 3, which is {d}: {l}\")\n",
    "\n",
    "# sort list\n",
    "l.sort()\n",
    "print('This is the list after sorting it:                       ', l)\n",
    "\n",
    "# reverse list\n",
    "l.reverse()\n",
    "print('This is the list after reversing it:                     ', l)\n",
    "\n",
    "\n",
    "# get count of items in a list\n",
    "print('number of items in the list:                             ', len(l))\n",
    "\n",
    "# access items in a list (zero-indexed)\n",
    "print('first item in the list:                                  ', l[0])\n",
    "\n",
    "# access the last item in a list\n",
    "print('last item in the list:                                   ', l[-1])\n",
    "\n",
    "# access a slice from the list\n",
    "print('from item of index \"1\" to item of index \"2\":             ', l[1:3]) \n",
    "print('from the first item to item of index \"1\":                ', l[:2])\n",
    "print('from item of index \"1\" to the last item:                 ', l[1:])\n",
    "\n",
    "# set item in a list\n",
    "l[1] = 2\n",
    "\n",
    "print('the list after changing the second item from \"NLP\" to 2: ', l)\n",
    "\n",
    "# remove item from list\n",
    "del l[0]\n",
    "\n",
    "print('the list after removing the first item:                  ', l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc33a03",
   "metadata": {},
   "source": [
    "### Dictionaries\n",
    "Dictionaries store data as (`key`, `value`) pairs of arbitrary types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acbfc8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item with a string key:               1\n",
      "item with an int key:                 3\n",
      "item with a float key:                4.5\n",
      "value of key 4.5:                     4.5\n",
      "dictionary after adding an item:      {'1': 1, '2': 2, 3: '3', 4.5: '4.5', 5: '5'}\n",
      "dictionary after updating an item:    {'1': 1, '2': 2, 3: '3', 4.5: '4.5', 5: 'five'}\n",
      "keys in the dictionary:               dict_keys(['1', '2', 3, 4.5, 5])\n",
      "values in the dictionary:             dict_values([1, 2, '3', '4.5', 'five'])\n",
      "items in the dictionary:              dict_items([('1', 1), ('2', 2), (3, '3'), (4.5, '4.5'), (5, 'five')])\n",
      "dictionary after popping the item with key '1', which is 1: {'2': 2, 3: '3', 4.5: '4.5', 5: 'five'}\n",
      "dictionary after deleting an item:    {3: '3', 4.5: '4.5', 5: 'five'}\n"
     ]
    }
   ],
   "source": [
    "d = {   \n",
    "        \"1\": 1, \n",
    "        \"2\": 2, \n",
    "        3: \"3\", \n",
    "        4.5:\"4.5\"\n",
    "    }\n",
    "print('item with a string key:              ', d[\"1\"])\n",
    "print('item with an int key:                ', d[3])\n",
    "print('item with a float key:               ', d[4.5])\n",
    "\n",
    "# get value of a specific key\n",
    "print('value of key 4.5:                    ', d.get(4.5))\n",
    "\n",
    "# add item to the dictionary\n",
    "d[5] = \"5\"\n",
    "print('dictionary after adding an item:     ', d)\n",
    "\n",
    "# update item in the dictionary\n",
    "d[5] = \"five\"\n",
    "print('dictionary after updating an item:   ', d)\n",
    "\n",
    "# print all keys in the dictionary\n",
    "print('keys in the dictionary:              ', d.keys())\n",
    "\n",
    "# print all values in the dictionary\n",
    "print('values in the dictionary:            ', d.values())\n",
    "\n",
    "# print all items in the dictionary\n",
    "print('items in the dictionary:             ', d.items())\n",
    "\n",
    "# pop item from the dictionary\n",
    "item=d.pop('1')\n",
    "print(f\"dictionary after popping the item with key '1', which is {item}: {d}\")\n",
    "\n",
    "\n",
    "# delete item with a specific key\n",
    "del d[\"2\"]\n",
    "print('dictionary after deleting an item:   ', d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb50cc",
   "metadata": {},
   "source": [
    "### Tuples\n",
    "Tuples are `immutable` objects, lists are `mutable`.\n",
    "\n",
    "Tuples cannot be changed while lists can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6a9a5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tuple:   (1, 2.5, '3')\n",
      "first item        1\n",
      "\n",
      "after adding 4:   (1, 2.5, '3', 4)\n",
      "tuple\n",
      "{(1, 2.5, '3', 4): 'tuple'}\n"
     ]
    }
   ],
   "source": [
    "t = (1, 2.5, \"3\")\n",
    "print('original tuple:  ', t)\n",
    "print('first item       ', t[0])\n",
    "print()\n",
    "\n",
    "\"\"\"\n",
    "Tuple is immutable, although you can use the + operator to concatenate several tuples.\n",
    " The old object is still present at this point, and a new object is created.\n",
    "\"\"\"\n",
    "t = t + (4,)\n",
    "print('after adding 4:  ', t)\n",
    "\n",
    "# tuples can be a key of a dict\n",
    "d = {t: \"tuple\"}\n",
    "print(d[t])\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ee489d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\CMP\\TA-CU\\All Courses\\NLP\\labs-github\\NLP-Course-CUFE\\labs\\Lab 0 - Introduction to Python\\Introduction to Python.ipynb Cell 18\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CMP/TA-CU/All%20Courses/NLP/labs-github/NLP-Course-CUFE/labs/Lab%200%20-%20Introduction%20to%20Python/Introduction%20to%20Python.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# this will get an error (recall: tuple are immutable)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CMP/TA-CU/All%20Courses/NLP/labs-github/NLP-Course-CUFE/labs/Lab%200%20-%20Introduction%20to%20Python/Introduction%20to%20Python.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# tuples are immutable so you can't change them\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/CMP/TA-CU/All%20Courses/NLP/labs-github/NLP-Course-CUFE/labs/Lab%200%20-%20Introduction%20to%20Python/Introduction%20to%20Python.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m t[\u001b[39m0\u001b[39;49m]\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# this will get an error (recall: tuple are immutable)\n",
    "# tuples are immutable so you can't change them\n",
    "t[0]=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4569543a",
   "metadata": {},
   "source": [
    "### Sets\n",
    "- `Unchangeable`: same as tuples\n",
    "- `unindexed`: we cannot access a specific index\n",
    "- `unique values only`: no duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef6b98f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a', 'c', 'b'}\n",
      "{5, 'c', 'b'}\n",
      "{5, 'c', 'b'}\n"
     ]
    }
   ],
   "source": [
    "s = {\"a\", \"b\", \"c\"}\n",
    "print(s)\n",
    "\n",
    "# add item to the set\n",
    "s.add(5)\n",
    "# remove item from the set\n",
    "s.remove(\"a\")\n",
    "print(s)\n",
    "\n",
    "# try adding duplicate items\n",
    "s = {5, \"b\", \"c\", \"b\"}\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d523783c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\CMP\\TA-CU\\All Courses\\NLP\\labs-github\\NLP-Course-CUFE\\labs\\Lab 0 - Introduction to Python\\Introduction to Python.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CMP/TA-CU/All%20Courses/NLP/labs-github/NLP-Course-CUFE/labs/Lab%200%20-%20Introduction%20to%20Python/Introduction%20to%20Python.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# this will get an error (recall: sets not subscriptable)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/CMP/TA-CU/All%20Courses/NLP/labs-github/NLP-Course-CUFE/labs/Lab%200%20-%20Introduction%20to%20Python/Introduction%20to%20Python.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m s[\u001b[39m0\u001b[39;49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# this will get an error (recall: sets not subscriptable)\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbf140a",
   "metadata": {},
   "source": [
    "### Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb11f604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', ' ', 'd', 'e', 'f']\n"
     ]
    }
   ],
   "source": [
    "# convert a string to a list of characters\n",
    "l=list(\"abc def\")\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71923714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'one', 'two'}\n"
     ]
    }
   ],
   "source": [
    "s= set([\"one\",\"two\",\"one\"])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aa7e5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['words', 'with', 'spaces']\n",
      "['1', '4', '8', '2']\n"
     ]
    }
   ],
   "source": [
    "w=\"words with spaces\".split() # split the string into a list of words\n",
    "print(w)\n",
    "\n",
    "# split the string on a specific character (,)\n",
    "n=\"1,4,8,2\".split(\",\")\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23dc4ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words with spaces\n",
      "1,4,8,2\n"
     ]
    }
   ],
   "source": [
    "# join the list of words into a string\n",
    "print(' '.join(w) )\n",
    "\n",
    "# join the list of words into a string with a comma between them\n",
    "print(','.join(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735bc2e1",
   "metadata": {},
   "source": [
    "### Arithmetic Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e66df76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "-1\n",
      "1.5\n",
      "1\n",
      "6\n",
      "1\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "x = 2\n",
    "y = 3\n",
    "print(x + y)\n",
    "print(x - y)\n",
    "print(y / x)\n",
    "print(y // x)\n",
    "print(x * y)\n",
    "print(y % x)\n",
    "print(x**y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2843f9f1",
   "metadata": {},
   "source": [
    "### Assignment operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f99ddc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "2\n",
      "1.0\n",
      "3.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "x = 2\n",
    "print(x)\n",
    "x += 1\n",
    "print(x)\n",
    "x -= 1\n",
    "print(x)\n",
    "x /= 2\n",
    "print(x)\n",
    "x *= 3\n",
    "print(x)\n",
    "x //= 2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5974f71",
   "metadata": {},
   "source": [
    "### Comparison operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad761d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = 3\n",
    "y = 2\n",
    "print(x == y)\n",
    "print(x != y)\n",
    "print(x >= y)\n",
    "print(x <= y)\n",
    "print(x > y)\n",
    "print(x < y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6901b21d",
   "metadata": {},
   "source": [
    "### Logical Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "655c3b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = True\n",
    "y = False\n",
    "print(x and y)\n",
    "print(x or y)\n",
    "print(not y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977c721e",
   "metadata": {},
   "source": [
    "# Flow Control\n",
    "`Blocks` in `Python` are structured using `indentation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e01df",
   "metadata": {},
   "source": [
    "### `if`-`elif`-`else`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b565f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x < y\n"
     ]
    }
   ],
   "source": [
    "x = 2\n",
    "y = 3\n",
    "if x > y:\n",
    "    # here indentation is important\n",
    "    print (\"x > y\")\n",
    "elif x < y:\n",
    "    print(\"x < y\")\n",
    "else:\n",
    "    print(\"x = y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8130c0b",
   "metadata": {},
   "source": [
    "### `while` loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7ba08e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# while loops\n",
    "i = 0\n",
    "while i < 10:\n",
    "    print(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a6afe",
   "metadata": {},
   "source": [
    "### `for` loops\n",
    "for is used to iterate over sequences like lists, dictionaries, sets, strings, tuples, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c99c712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5.3\n",
      "\n",
      "[2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[2, 4, 6, 8]\n",
      "\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "N\n",
      "L\n",
      "P\n"
     ]
    }
   ],
   "source": [
    "l = [\"1\", \"2\", 3, 4, 5.3]\n",
    "for item in l:\n",
    "    print(item)\n",
    "    \n",
    "print()\n",
    "\n",
    "# range function\n",
    "print(list(range(2, 10)))\n",
    "print(list(range(10)))\n",
    "print(list(range(2, 10, 2)))\n",
    "print()\n",
    "\n",
    "for i in range(2, 10):\n",
    "    print(i)\n",
    "    \n",
    "print()\n",
    "\n",
    "s = \"NLP\"\n",
    "for c in s:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b1c093",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be7868ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function with no arguments\n",
    "def func():\n",
    "    print(\"in func\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99620132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in func\n"
     ]
    }
   ],
   "source": [
    "func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2e643ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function with arguments\n",
    "def func(a):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e81f703a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "func(3)\n",
    "func([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d958ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that makes some logic and returns a value\n",
    "def func(a):\n",
    "    return a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf7be4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "f = func(3)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72675e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes a variable number of arguments\n",
    "def func(*args):\n",
    "    for arg in args:\n",
    "        print(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31d953f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "NLP\n"
     ]
    }
   ],
   "source": [
    "func(1, 2, \"NLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f914bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function with 3 arguments\n",
    "def func(a, b, c):\n",
    "    print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f21853a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n",
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "func(1, 2, 3)\n",
    "func(b=2, a=1, c=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f0edb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function with an argument that has a default value\n",
    "def func(a,b=1):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a142cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 5\n",
      "2 1\n"
     ]
    }
   ],
   "source": [
    "func(2,5)\n",
    "func(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c3cdf40",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (25820532.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[38], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    def func(b=9,a):\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "# get an error (non-default argument follows default argument)\n",
    "def func(b=9,a):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e20ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function with a keyword arguments\n",
    "def func(**kwargs):\n",
    "    print(kwargs[\"subject\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42aae6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP\n"
     ]
    }
   ],
   "source": [
    "func(subject=\"NLP\", section=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb02733b",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7adc17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        print(\"Human created\")\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"My name is {self.name}\"\n",
    "    \n",
    "    def changeName(self, name):\n",
    "        print(f\"replacing {self.name} with {name}\")\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84f0f220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human created\n",
      "My name is omar\n",
      "replacing omar with mohamed\n",
      "My name is mohamed\n"
     ]
    }
   ],
   "source": [
    "h = Human(\"omar\")\n",
    "print(h)\n",
    "h.changeName(\"mohamed\")\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3e78432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student(Human):\n",
    "    def __init__(self, name, year):\n",
    "        Human.__init__(self, name)\n",
    "        self.year = year\n",
    "        print(\"Student created\")\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"Student name: {self.name}\\nIn year: {self.year}\"\n",
    "    \n",
    "    def passed(self):\n",
    "        self.year += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd53b979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human created\n",
      "Student created\n",
      "Student name: omar\n",
      "In year: 4\n",
      "Student name: omar\n",
      "In year: 5\n"
     ]
    }
   ],
   "source": [
    "s = Student(\"omar\", 4)\n",
    "print(s)\n",
    "s.passed()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2a6132",
   "metadata": {},
   "source": [
    "# Towards Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "50a7c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Language Toolkit\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06e3b0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'book'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\omars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection book\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99aac30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "831ff216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d556fe28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b06dc8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "# search for a specific word in a text\n",
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aaec2642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44764"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of tokens in a given text (words and punctuation symbols)\n",
    "len(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2bbc533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ',)',\n",
       " '.',\n",
       " '.)',\n",
       " ':',\n",
       " ';',\n",
       " ';)',\n",
       " '?',\n",
       " '?)',\n",
       " 'A',\n",
       " 'Abel',\n",
       " 'Abelmizraim',\n",
       " 'Abidah',\n",
       " 'Abide',\n",
       " 'Abimael',\n",
       " 'Abimelech',\n",
       " 'Abr',\n",
       " 'Abrah',\n",
       " 'Abraham',\n",
       " 'Abram',\n",
       " 'Accad',\n",
       " 'Achbor',\n",
       " 'Adah',\n",
       " 'Adam',\n",
       " 'Adbeel',\n",
       " 'Admah',\n",
       " 'Adullamite',\n",
       " 'After',\n",
       " 'Aholibamah',\n",
       " 'Ahuzzath',\n",
       " 'Ajah',\n",
       " 'Akan',\n",
       " 'All',\n",
       " 'Allonbachuth',\n",
       " 'Almighty',\n",
       " 'Almodad',\n",
       " 'Also',\n",
       " 'Alvah',\n",
       " 'Alvan',\n",
       " 'Am',\n",
       " 'Amal',\n",
       " 'Amalek',\n",
       " 'Amalekites',\n",
       " 'Ammon',\n",
       " 'Amorite',\n",
       " 'Amorites',\n",
       " 'Amraphel',\n",
       " 'An',\n",
       " 'Anah',\n",
       " 'Anamim',\n",
       " 'And',\n",
       " 'Aner',\n",
       " 'Angel',\n",
       " 'Appoint',\n",
       " 'Aram',\n",
       " 'Aran',\n",
       " 'Ararat',\n",
       " 'Arbah',\n",
       " 'Ard',\n",
       " 'Are',\n",
       " 'Areli',\n",
       " 'Arioch',\n",
       " 'Arise',\n",
       " 'Arkite',\n",
       " 'Arodi',\n",
       " 'Arphaxad',\n",
       " 'Art',\n",
       " 'Arvadite',\n",
       " 'As',\n",
       " 'Asenath',\n",
       " 'Ashbel',\n",
       " 'Asher',\n",
       " 'Ashkenaz',\n",
       " 'Ashteroth',\n",
       " 'Ask',\n",
       " 'Asshur',\n",
       " 'Asshurim',\n",
       " 'Assyr',\n",
       " 'Assyria',\n",
       " 'At',\n",
       " 'Atad',\n",
       " 'Avith',\n",
       " 'Baalhanan',\n",
       " 'Babel',\n",
       " 'Bashemath',\n",
       " 'Be',\n",
       " 'Because',\n",
       " 'Becher',\n",
       " 'Bedad',\n",
       " 'Beeri',\n",
       " 'Beerlahairoi',\n",
       " 'Beersheba',\n",
       " 'Behold',\n",
       " 'Bela',\n",
       " 'Belah',\n",
       " 'Benam',\n",
       " 'Benjamin',\n",
       " 'Beno',\n",
       " 'Beor',\n",
       " 'Bera',\n",
       " 'Bered',\n",
       " 'Beriah',\n",
       " 'Bethel',\n",
       " 'Bethlehem',\n",
       " 'Bethuel',\n",
       " 'Beware',\n",
       " 'Bilhah',\n",
       " 'Bilhan',\n",
       " 'Binding',\n",
       " 'Birsha',\n",
       " 'Bless',\n",
       " 'Blessed',\n",
       " 'Both',\n",
       " 'Bow',\n",
       " 'Bozrah',\n",
       " 'Bring',\n",
       " 'But',\n",
       " 'Buz',\n",
       " 'By',\n",
       " 'Cain',\n",
       " 'Cainan',\n",
       " 'Calah',\n",
       " 'Calneh',\n",
       " 'Can',\n",
       " 'Cana',\n",
       " 'Canaan',\n",
       " 'Canaanite',\n",
       " 'Canaanites',\n",
       " 'Canaanitish',\n",
       " 'Caphtorim',\n",
       " 'Carmi',\n",
       " 'Casluhim',\n",
       " 'Cast',\n",
       " 'Cause',\n",
       " 'Chaldees',\n",
       " 'Chedorlaomer',\n",
       " 'Cheran',\n",
       " 'Cherubims',\n",
       " 'Chesed',\n",
       " 'Chezib',\n",
       " 'Come',\n",
       " 'Cursed',\n",
       " 'Cush',\n",
       " 'Damascus',\n",
       " 'Dan',\n",
       " 'Day',\n",
       " 'Deborah',\n",
       " 'Dedan',\n",
       " 'Deliver',\n",
       " 'Diklah',\n",
       " 'Din',\n",
       " 'Dinah',\n",
       " 'Dinhabah',\n",
       " 'Discern',\n",
       " 'Dishan',\n",
       " 'Dishon',\n",
       " 'Do',\n",
       " 'Dodanim',\n",
       " 'Dothan',\n",
       " 'Drink',\n",
       " 'Duke',\n",
       " 'Dumah',\n",
       " 'Earth',\n",
       " 'Ebal',\n",
       " 'Eber',\n",
       " 'Edar',\n",
       " 'Eden',\n",
       " 'Edom',\n",
       " 'Edomites',\n",
       " 'Egy',\n",
       " 'Egypt',\n",
       " 'Egyptia',\n",
       " 'Egyptian',\n",
       " 'Egyptians',\n",
       " 'Ehi',\n",
       " 'Elah',\n",
       " 'Elam',\n",
       " 'Elbethel',\n",
       " 'Eldaah',\n",
       " 'EleloheIsrael',\n",
       " 'Eliezer',\n",
       " 'Eliphaz',\n",
       " 'Elishah',\n",
       " 'Ellasar',\n",
       " 'Elon',\n",
       " 'Elparan',\n",
       " 'Emins',\n",
       " 'En',\n",
       " 'Enmishpat',\n",
       " 'Eno',\n",
       " 'Enoch',\n",
       " 'Enos',\n",
       " 'Ephah',\n",
       " 'Epher',\n",
       " 'Ephra',\n",
       " 'Ephraim',\n",
       " 'Ephrath',\n",
       " 'Ephron',\n",
       " 'Er',\n",
       " 'Erech',\n",
       " 'Eri',\n",
       " 'Es',\n",
       " 'Esau',\n",
       " 'Escape',\n",
       " 'Esek',\n",
       " 'Eshban',\n",
       " 'Eshcol',\n",
       " 'Ethiopia',\n",
       " 'Euphrat',\n",
       " 'Euphrates',\n",
       " 'Eve',\n",
       " 'Even',\n",
       " 'Every',\n",
       " 'Except',\n",
       " 'Ezbon',\n",
       " 'Ezer',\n",
       " 'Fear',\n",
       " 'Feed',\n",
       " 'Fifteen',\n",
       " 'Fill',\n",
       " 'For',\n",
       " 'Forasmuch',\n",
       " 'Forgive',\n",
       " 'From',\n",
       " 'Fulfil',\n",
       " 'G',\n",
       " 'Gad',\n",
       " 'Gaham',\n",
       " 'Galeed',\n",
       " 'Gatam',\n",
       " 'Gather',\n",
       " 'Gaza',\n",
       " 'Gentiles',\n",
       " 'Gera',\n",
       " 'Gerar',\n",
       " 'Gershon',\n",
       " 'Get',\n",
       " 'Gether',\n",
       " 'Gihon',\n",
       " 'Gilead',\n",
       " 'Girgashites',\n",
       " 'Girgasite',\n",
       " 'Give',\n",
       " 'Go',\n",
       " 'God',\n",
       " 'Gomer',\n",
       " 'Gomorrah',\n",
       " 'Goshen',\n",
       " 'Guni',\n",
       " 'Hadad',\n",
       " 'Hadar',\n",
       " 'Hadoram',\n",
       " 'Hagar',\n",
       " 'Haggi',\n",
       " 'Hai',\n",
       " 'Ham',\n",
       " 'Hamathite',\n",
       " 'Hamor',\n",
       " 'Hamul',\n",
       " 'Hanoch',\n",
       " 'Happy',\n",
       " 'Haran',\n",
       " 'Hast',\n",
       " 'Haste',\n",
       " 'Have',\n",
       " 'Havilah',\n",
       " 'Hazarmaveth',\n",
       " 'Hazezontamar',\n",
       " 'Hazo',\n",
       " 'He',\n",
       " 'Hear',\n",
       " 'Heaven',\n",
       " 'Heber',\n",
       " 'Hebrew',\n",
       " 'Hebrews',\n",
       " 'Hebron',\n",
       " 'Hemam',\n",
       " 'Hemdan',\n",
       " 'Here',\n",
       " 'Hereby',\n",
       " 'Heth',\n",
       " 'Hezron',\n",
       " 'Hiddekel',\n",
       " 'Hinder',\n",
       " 'Hirah',\n",
       " 'His',\n",
       " 'Hitti',\n",
       " 'Hittite',\n",
       " 'Hittites',\n",
       " 'Hivite',\n",
       " 'Hobah',\n",
       " 'Hori',\n",
       " 'Horite',\n",
       " 'Horites',\n",
       " 'How',\n",
       " 'Hul',\n",
       " 'Huppim',\n",
       " 'Husham',\n",
       " 'Hushim',\n",
       " 'Huz',\n",
       " 'I',\n",
       " 'If',\n",
       " 'In',\n",
       " 'Irad',\n",
       " 'Iram',\n",
       " 'Is',\n",
       " 'Isa',\n",
       " 'Isaac',\n",
       " 'Iscah',\n",
       " 'Ishbak',\n",
       " 'Ishmael',\n",
       " 'Ishmeelites',\n",
       " 'Ishuah',\n",
       " 'Isra',\n",
       " 'Israel',\n",
       " 'Issachar',\n",
       " 'Isui',\n",
       " 'It',\n",
       " 'Ithran',\n",
       " 'Jaalam',\n",
       " 'Jabal',\n",
       " 'Jabbok',\n",
       " 'Jac',\n",
       " 'Jachin',\n",
       " 'Jacob',\n",
       " 'Jahleel',\n",
       " 'Jahzeel',\n",
       " 'Jamin',\n",
       " 'Japhe',\n",
       " 'Japheth',\n",
       " 'Jared',\n",
       " 'Javan',\n",
       " 'Jebusite',\n",
       " 'Jebusites',\n",
       " 'Jegarsahadutha',\n",
       " 'Jehovahjireh',\n",
       " 'Jemuel',\n",
       " 'Jerah',\n",
       " 'Jetheth',\n",
       " 'Jetur',\n",
       " 'Jeush',\n",
       " 'Jezer',\n",
       " 'Jidlaph',\n",
       " 'Jimnah',\n",
       " 'Job',\n",
       " 'Jobab',\n",
       " 'Jokshan',\n",
       " 'Joktan',\n",
       " 'Jordan',\n",
       " 'Joseph',\n",
       " 'Jubal',\n",
       " 'Judah',\n",
       " 'Judge',\n",
       " 'Judith',\n",
       " 'Kadesh',\n",
       " 'Kadmonites',\n",
       " 'Karnaim',\n",
       " 'Kedar',\n",
       " 'Kedemah',\n",
       " 'Kemuel',\n",
       " 'Kenaz',\n",
       " 'Kenites',\n",
       " 'Kenizzites',\n",
       " 'Keturah',\n",
       " 'Kiriathaim',\n",
       " 'Kirjatharba',\n",
       " 'Kittim',\n",
       " 'Know',\n",
       " 'Kohath',\n",
       " 'Kor',\n",
       " 'Korah',\n",
       " 'LO',\n",
       " 'LORD',\n",
       " 'Laban',\n",
       " 'Lahairoi',\n",
       " 'Lamech',\n",
       " 'Lasha',\n",
       " 'Lay',\n",
       " 'Leah',\n",
       " 'Lehabim',\n",
       " 'Lest',\n",
       " 'Let',\n",
       " 'Letushim',\n",
       " 'Leummim',\n",
       " 'Levi',\n",
       " 'Lie',\n",
       " 'Lift',\n",
       " 'Lo',\n",
       " 'Look',\n",
       " 'Lot',\n",
       " 'Lotan',\n",
       " 'Lud',\n",
       " 'Ludim',\n",
       " 'Luz',\n",
       " 'Maachah',\n",
       " 'Machir',\n",
       " 'Machpelah',\n",
       " 'Madai',\n",
       " 'Magdiel',\n",
       " 'Magog',\n",
       " 'Mahalaleel',\n",
       " 'Mahalath',\n",
       " 'Mahanaim',\n",
       " 'Make',\n",
       " 'Malchiel',\n",
       " 'Male',\n",
       " 'Mam',\n",
       " 'Mamre',\n",
       " 'Man',\n",
       " 'Manahath',\n",
       " 'Manass',\n",
       " 'Manasseh',\n",
       " 'Mash',\n",
       " 'Masrekah',\n",
       " 'Massa',\n",
       " 'Matred',\n",
       " 'Me',\n",
       " 'Medan',\n",
       " 'Mehetabel',\n",
       " 'Mehujael',\n",
       " 'Melchizedek',\n",
       " 'Merari',\n",
       " 'Mesha',\n",
       " 'Meshech',\n",
       " 'Mesopotamia',\n",
       " 'Methusa',\n",
       " 'Methusael',\n",
       " 'Methuselah',\n",
       " 'Mezahab',\n",
       " 'Mibsam',\n",
       " 'Mibzar',\n",
       " 'Midian',\n",
       " 'Midianites',\n",
       " 'Milcah',\n",
       " 'Mishma',\n",
       " 'Mizpah',\n",
       " 'Mizraim',\n",
       " 'Mizz',\n",
       " 'Moab',\n",
       " 'Moabites',\n",
       " 'Moreh',\n",
       " 'Moreover',\n",
       " 'Moriah',\n",
       " 'Muppim',\n",
       " 'My',\n",
       " 'Naamah',\n",
       " 'Naaman',\n",
       " 'Nahath',\n",
       " 'Nahor',\n",
       " 'Naphish',\n",
       " 'Naphtali',\n",
       " 'Naphtuhim',\n",
       " 'Nay',\n",
       " 'Nebajoth',\n",
       " 'Neither',\n",
       " 'Night',\n",
       " 'Nimrod',\n",
       " 'Nineveh',\n",
       " 'Noah',\n",
       " 'Nod',\n",
       " 'Not',\n",
       " 'Now',\n",
       " 'O',\n",
       " 'Obal',\n",
       " 'Of',\n",
       " 'Oh',\n",
       " 'Ohad',\n",
       " 'Omar',\n",
       " 'On',\n",
       " 'Onam',\n",
       " 'Onan',\n",
       " 'Only',\n",
       " 'Ophir',\n",
       " 'Our',\n",
       " 'Out',\n",
       " 'Padan',\n",
       " 'Padanaram',\n",
       " 'Paran',\n",
       " 'Pass',\n",
       " 'Pathrusim',\n",
       " 'Pau',\n",
       " 'Peace',\n",
       " 'Peleg',\n",
       " 'Peniel',\n",
       " 'Penuel',\n",
       " 'Peradventure',\n",
       " 'Perizzit',\n",
       " 'Perizzite',\n",
       " 'Perizzites',\n",
       " 'Phallu',\n",
       " 'Phara',\n",
       " 'Pharaoh',\n",
       " 'Pharez',\n",
       " 'Phichol',\n",
       " 'Philistim',\n",
       " 'Philistines',\n",
       " 'Phut',\n",
       " 'Phuvah',\n",
       " 'Pildash',\n",
       " 'Pinon',\n",
       " 'Pison',\n",
       " 'Potiphar',\n",
       " 'Potipherah',\n",
       " 'Put',\n",
       " 'Raamah',\n",
       " 'Rachel',\n",
       " 'Rameses',\n",
       " 'Rebek',\n",
       " 'Rebekah',\n",
       " 'Rehoboth',\n",
       " 'Remain',\n",
       " 'Rephaims',\n",
       " 'Resen',\n",
       " 'Return',\n",
       " 'Reu',\n",
       " 'Reub',\n",
       " 'Reuben',\n",
       " 'Reuel',\n",
       " 'Reumah',\n",
       " 'Riphath',\n",
       " 'Rosh',\n",
       " 'Sabtah',\n",
       " 'Sabtech',\n",
       " 'Said',\n",
       " 'Salah',\n",
       " 'Salem',\n",
       " 'Samlah',\n",
       " 'Sarah',\n",
       " 'Sarai',\n",
       " 'Saul',\n",
       " 'Save',\n",
       " 'Say',\n",
       " 'Se',\n",
       " 'Seba',\n",
       " 'See',\n",
       " 'Seeing',\n",
       " 'Seir',\n",
       " 'Sell',\n",
       " 'Send',\n",
       " 'Sephar',\n",
       " 'Serah',\n",
       " 'Sered',\n",
       " 'Serug',\n",
       " 'Set',\n",
       " 'Seth',\n",
       " 'Shalem',\n",
       " 'Shall',\n",
       " 'Shalt',\n",
       " 'Shammah',\n",
       " 'Shaul',\n",
       " 'Shaveh',\n",
       " 'She',\n",
       " 'Sheba',\n",
       " 'Shebah',\n",
       " 'Shechem',\n",
       " 'Shed',\n",
       " 'Shel',\n",
       " 'Shelah',\n",
       " 'Sheleph',\n",
       " 'Shem',\n",
       " 'Shemeber',\n",
       " 'Shepho',\n",
       " 'Shillem',\n",
       " 'Shiloh',\n",
       " 'Shimron',\n",
       " 'Shinab',\n",
       " 'Shinar',\n",
       " 'Shobal',\n",
       " 'Should',\n",
       " 'Shuah',\n",
       " 'Shuni',\n",
       " 'Shur',\n",
       " 'Sichem',\n",
       " 'Siddim',\n",
       " 'Sidon',\n",
       " 'Simeon',\n",
       " 'Sinite',\n",
       " 'Sitnah',\n",
       " 'Slay',\n",
       " 'So',\n",
       " 'Sod',\n",
       " 'Sodom',\n",
       " 'Sojourn',\n",
       " 'Some',\n",
       " 'Spake',\n",
       " 'Speak',\n",
       " 'Spirit',\n",
       " 'Stand',\n",
       " 'Succoth',\n",
       " 'Surely',\n",
       " 'Swear',\n",
       " 'Syrian',\n",
       " 'Take',\n",
       " 'Tamar',\n",
       " 'Tarshish',\n",
       " 'Tebah',\n",
       " 'Tell',\n",
       " 'Tema',\n",
       " 'Teman',\n",
       " 'Temani',\n",
       " 'Terah',\n",
       " 'Thahash',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'Therefore',\n",
       " 'These',\n",
       " 'They',\n",
       " 'Thirty',\n",
       " 'This',\n",
       " 'Thorns',\n",
       " 'Thou',\n",
       " 'Thus',\n",
       " 'Thy',\n",
       " 'Tidal',\n",
       " 'Timna',\n",
       " 'Timnah',\n",
       " 'Timnath',\n",
       " 'Tiras',\n",
       " 'To',\n",
       " 'Togarmah',\n",
       " 'Tola',\n",
       " 'Tubal',\n",
       " 'Tubalcain',\n",
       " 'Twelve',\n",
       " 'Two',\n",
       " 'Unstable',\n",
       " 'Until',\n",
       " 'Unto',\n",
       " 'Up',\n",
       " 'Upon',\n",
       " 'Ur',\n",
       " 'Uz',\n",
       " 'Uzal',\n",
       " 'We',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Whence',\n",
       " 'Where',\n",
       " 'Whereas',\n",
       " 'Wherefore',\n",
       " 'Which',\n",
       " 'While',\n",
       " 'Who',\n",
       " 'Whose',\n",
       " 'Whoso',\n",
       " 'Why',\n",
       " 'Wilt',\n",
       " 'With',\n",
       " 'Woman',\n",
       " 'Ye',\n",
       " 'Yea',\n",
       " 'Yet',\n",
       " 'Zaavan',\n",
       " 'Zaphnathpaaneah',\n",
       " 'Zar',\n",
       " 'Zarah',\n",
       " 'Zeboiim',\n",
       " 'Zeboim',\n",
       " 'Zebul',\n",
       " 'Zebulun',\n",
       " 'Zemarite',\n",
       " 'Zepho',\n",
       " 'Zerah',\n",
       " 'Zibeon',\n",
       " 'Zidon',\n",
       " 'Zillah',\n",
       " 'Zilpah',\n",
       " 'Zimran',\n",
       " 'Ziphion',\n",
       " 'Zo',\n",
       " 'Zoar',\n",
       " 'Zohar',\n",
       " 'Zuzims',\n",
       " 'a',\n",
       " 'abated',\n",
       " 'abide',\n",
       " 'able',\n",
       " 'abode',\n",
       " 'abomination',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absent',\n",
       " 'abundantly',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'according',\n",
       " 'acknowledged',\n",
       " 'activity',\n",
       " 'add',\n",
       " 'adder',\n",
       " 'afar',\n",
       " 'afflict',\n",
       " 'affliction',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'aga',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aileth',\n",
       " 'air',\n",
       " 'al',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'almon',\n",
       " 'alo',\n",
       " 'alone',\n",
       " 'aloud',\n",
       " 'also',\n",
       " 'altar',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'anointedst',\n",
       " 'anoth',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'any',\n",
       " 'anything',\n",
       " 'appe',\n",
       " 'appear',\n",
       " 'appeared',\n",
       " 'appease',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'aprons',\n",
       " 'archer',\n",
       " 'archers',\n",
       " 'are',\n",
       " 'arise',\n",
       " 'ark',\n",
       " 'armed',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arose',\n",
       " 'arrayed',\n",
       " 'art',\n",
       " 'artificer',\n",
       " 'as',\n",
       " 'ascending',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asketh',\n",
       " 'ass',\n",
       " 'assembly',\n",
       " 'asses',\n",
       " 'assigned',\n",
       " 'asswaged',\n",
       " 'at',\n",
       " 'attained',\n",
       " 'audience',\n",
       " 'avenged',\n",
       " 'aw',\n",
       " 'awaked',\n",
       " 'away',\n",
       " 'awoke',\n",
       " 'back',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bade',\n",
       " 'badest',\n",
       " 'badne',\n",
       " 'bak',\n",
       " 'bake',\n",
       " 'bakemeats',\n",
       " 'baker',\n",
       " 'bakers',\n",
       " 'balm',\n",
       " 'bands',\n",
       " 'bank',\n",
       " 'bare',\n",
       " 'barr',\n",
       " 'barren',\n",
       " 'basket',\n",
       " 'baskets',\n",
       " 'battle',\n",
       " 'bdellium',\n",
       " 'be',\n",
       " 'bear',\n",
       " 'beari',\n",
       " 'bearing',\n",
       " 'beast',\n",
       " 'beasts',\n",
       " 'beautiful',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'befall',\n",
       " 'befell',\n",
       " 'before',\n",
       " 'began',\n",
       " 'begat',\n",
       " 'beget',\n",
       " 'begettest',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begotten',\n",
       " 'beguiled',\n",
       " 'beheld',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'being',\n",
       " 'believed',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'beneath',\n",
       " 'bereaved',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'besought',\n",
       " 'best',\n",
       " 'betimes',\n",
       " 'better',\n",
       " 'between',\n",
       " 'betwixt',\n",
       " 'beyond',\n",
       " 'binding',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birthday',\n",
       " 'birthright',\n",
       " 'biteth',\n",
       " 'bitter',\n",
       " 'blame',\n",
       " 'blameless',\n",
       " 'blasted',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blesseth',\n",
       " 'blessi',\n",
       " 'blessing',\n",
       " 'blessings',\n",
       " 'blindness',\n",
       " 'blood',\n",
       " 'blossoms',\n",
       " 'bodies',\n",
       " 'boldly',\n",
       " 'bondman',\n",
       " 'bondmen',\n",
       " 'bondwoman',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'book',\n",
       " 'booths',\n",
       " 'border',\n",
       " 'borders',\n",
       " 'born',\n",
       " 'bosom',\n",
       " 'both',\n",
       " 'bottle',\n",
       " 'bou',\n",
       " 'boug',\n",
       " 'bough',\n",
       " 'bought',\n",
       " 'bound',\n",
       " 'bow',\n",
       " 'bowed',\n",
       " 'bowels',\n",
       " 'bowing',\n",
       " 'boys',\n",
       " 'bracelets',\n",
       " 'branches',\n",
       " 'brass',\n",
       " 'bre',\n",
       " 'breach',\n",
       " 'bread',\n",
       " 'breadth',\n",
       " 'break',\n",
       " 'breaketh',\n",
       " 'breaking',\n",
       " 'breasts',\n",
       " 'breath',\n",
       " 'breathed',\n",
       " 'breed',\n",
       " 'brethren',\n",
       " 'brick',\n",
       " 'brimstone',\n",
       " 'bring',\n",
       " 'brink',\n",
       " 'broken',\n",
       " 'brook',\n",
       " 'broth',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'bruise',\n",
       " 'budded',\n",
       " 'build',\n",
       " 'builded',\n",
       " 'built',\n",
       " 'bulls',\n",
       " 'bundle',\n",
       " 'bundles',\n",
       " 'burdens',\n",
       " 'buried',\n",
       " 'burn',\n",
       " 'burning',\n",
       " 'burnt',\n",
       " 'bury',\n",
       " 'buryingplace',\n",
       " 'business',\n",
       " 'but',\n",
       " 'butler',\n",
       " 'butlers',\n",
       " 'butlership',\n",
       " 'butter',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'cakes',\n",
       " 'calf',\n",
       " 'call',\n",
       " 'called',\n",
       " 'came',\n",
       " 'camel',\n",
       " 'camels',\n",
       " 'camest',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'canst',\n",
       " 'captain',\n",
       " 'captive',\n",
       " 'captives',\n",
       " 'carcases',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'cast',\n",
       " 'castles',\n",
       " 'catt',\n",
       " 'cattle',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'cave',\n",
       " 'cease',\n",
       " 'ceased',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'chamber',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'chariot',\n",
       " 'chariots',\n",
       " 'chesnut',\n",
       " 'chi',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childless',\n",
       " 'childr',\n",
       " 'children',\n",
       " 'chode',\n",
       " 'choice',\n",
       " 'chose',\n",
       " 'circumcis',\n",
       " 'circumcise',\n",
       " 'circumcised',\n",
       " 'citi',\n",
       " 'cities',\n",
       " 'city',\n",
       " 'clave',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'cleave',\n",
       " 'clo',\n",
       " 'closed',\n",
       " 'clothed',\n",
       " 'clothes',\n",
       " 'cloud',\n",
       " 'clusters',\n",
       " 'co',\n",
       " 'coat',\n",
       " 'coats',\n",
       " 'coffin',\n",
       " 'cold',\n",
       " ...]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to obtain the vocabulary of a given corpora (the unique words and punctuations)\n",
    "sorted(set(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1cda67e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2789\n",
      "44764\n",
      "6.230453042623537\n"
     ]
    }
   ],
   "source": [
    "print(len(set(text3)))\n",
    "print(len(text3))\n",
    "print(len(set(text3)) / len(text3) * 100)\n",
    "# what do you reveal comparing then number of tokens with the vocabulary number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e706fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to compute the number of occurances of a specific word\n",
    "text3.count(\"I\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a7446d",
   "metadata": {},
   "source": [
    "# Let's think about Text\n",
    "\n",
    "A text is a sequence of words and character (tokens) separated by white spaces, new lines, ...\n",
    "We can simply represent any corpora as a sequence of tokens so in python it is simply a list. This is how nltk represents text corporas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c54d9eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "sent1 = ['Call', 'me', 'Ishmael', '.']\n",
    "\n",
    "# to see the total number of tokens\n",
    "print(len(sent1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "639a6a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'family',\n",
       " 'of',\n",
       " 'Dashwood',\n",
       " 'had',\n",
       " 'long',\n",
       " 'been',\n",
       " 'settled',\n",
       " 'in',\n",
       " 'Sussex',\n",
       " '.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0f68201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'God',\n",
       " 'created',\n",
       " 'the',\n",
       " 'heaven',\n",
       " 'and',\n",
       " 'the',\n",
       " 'earth',\n",
       " '.']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "84b77e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'family',\n",
       " 'of',\n",
       " 'Dashwood',\n",
       " 'had',\n",
       " 'long',\n",
       " 'been',\n",
       " 'settled',\n",
       " 'in',\n",
       " 'Sussex',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'God',\n",
       " 'created',\n",
       " 'the',\n",
       " 'heaven',\n",
       " 'and',\n",
       " 'the',\n",
       " 'earth',\n",
       " '.']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to concatenate two sentences (lists)\n",
    "sent2 + sent3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f762759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call', 'me', 'Ishmael', '.', 'Some']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to add new token to a sentence\n",
    "sent1.append('Some')\n",
    "sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "abe45793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awaken'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to index a sentence (list) by index\n",
    "text4[173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "690511fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the first index of a specific word\n",
    "text4.index('awaken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a00a1eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U86',\n",
       " 'thats',\n",
       " 'why',\n",
       " 'something',\n",
       " 'like',\n",
       " 'gamefly',\n",
       " 'is',\n",
       " 'so',\n",
       " 'good',\n",
       " 'because',\n",
       " 'you',\n",
       " 'can',\n",
       " 'actually',\n",
       " 'play',\n",
       " 'a',\n",
       " 'full',\n",
       " 'game',\n",
       " 'without',\n",
       " 'buying',\n",
       " 'it']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use list slicing to get a part of the text\n",
    "text5[16715:16735]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ecabbace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.probability.FreqDist'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 18713),\n",
       " ('the', 13721),\n",
       " ('.', 6862),\n",
       " ('of', 6536),\n",
       " ('and', 6024),\n",
       " ('a', 4569),\n",
       " ('to', 4542),\n",
       " (';', 4072),\n",
       " ('in', 3916),\n",
       " ('that', 2982)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To calculate the word count of a corpora\n",
    "fdist1 = FreqDist(text1)\n",
    "print(type(fdist1))\n",
    "fdist1.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34e79117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1['whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f3599fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['superstitiousness',\n",
       " 'characteristically',\n",
       " 'uncomfortableness',\n",
       " 'circumnavigation',\n",
       " 'uninterpenetratingly',\n",
       " 'indispensableness',\n",
       " 'comprehensiveness',\n",
       " 'cannibalistically',\n",
       " 'preternaturalness',\n",
       " 'circumnavigating',\n",
       " 'Physiognomically',\n",
       " 'responsibilities',\n",
       " 'circumnavigations',\n",
       " 'undiscriminating',\n",
       " 'apprehensiveness',\n",
       " 'uncompromisedness',\n",
       " 'subterraneousness',\n",
       " 'physiognomically',\n",
       " 'simultaneousness',\n",
       " 'hermaphroditical',\n",
       " 'CIRCUMNAVIGATION',\n",
       " 'irresistibleness',\n",
       " 'indiscriminately',\n",
       " 'supernaturalness']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To filter words based on the word length\n",
    "# let's get the words having more than 15 character\n",
    "long_words = [w for w in set(text1) if len(w) > 15]\n",
    "long_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "607a2448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'hi', '?', 'you', 'to', 'JOIN', ',', 'I', '.', 'lol', 'a', 'the', 'PART']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what about filtering based on the word frequency in the corpora?\n",
    "fdist5 = FreqDist(text5)\n",
    "common_words = [w for w in set(text5) if fdist5[w] > 500]\n",
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "811c9024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# python built-in string comaprison operators\n",
    "\n",
    "# checks if string starts with sub-string\n",
    "print(\"omar\".startswith('o'))\n",
    "# checks if string ends with sub-string\n",
    "print(\"omar\".endswith('r'))\n",
    "# checks if string is sub-string of another\n",
    "print(\"ma\" in \"omar\")\n",
    "# checks if all characters in the string are lowercase\n",
    "print(\"omar\".islower())\n",
    "# checks if all characters in the string are uppercase\n",
    "print(\"OMAR\".isupper())\n",
    "# checks if all the characters in a string are alphabetic characters (a-z) only\n",
    "print(\"omar\".isalpha())\n",
    "# checks if all the characters are alphanumeric (a-z, 0-9) only\n",
    "print(\"omar1\".isalnum())\n",
    "# checks if all the characters are numeric (0-9) only\n",
    "print(\"123\".isdigit())\n",
    "# checks if the string is title-cased. (all words in a string begin with uppercase letters and the remaining characters are lowercase letters)\n",
    "print(\"Introduction To Python\".istitle())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff791e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
